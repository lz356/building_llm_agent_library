{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Run in Google Colab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1XjYLeIpysrrd53E-w1TtuOCWnr0RWJst?usp=sharing)"
      ],
      "metadata": {
        "id": "CgLgfUb-9X4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Packages\n",
        "!pip install langgraph==0.2.4\n",
        "!pip install langchain-community==0.2.12\n",
        "!pip install langchain-openai==0.1.22\n",
        "!pip install langchain-experimental==0.0.64"
      ],
      "metadata": {
        "id": "YdcbLq61902w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "\n",
        "# Placeholder to import tools and create tool list. Example:\n",
        "# from tools.tool_x import tool_x\n",
        "# from existing_agent_tool_library import tool_y\n",
        "# …\n",
        "# tool_list = [tool_x, tool_y, …]\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]\n",
        "\n",
        "class Agent:\n",
        "\n",
        "    def __init__(self, model, tools, system=\"\"):\n",
        "        self.system = system\n",
        "        graph = StateGraph(AgentState)\n",
        "\n",
        "        # Placeholder to create agent nodes and action nodes. Example:\n",
        "        # graph.add_node(\"agent_node_1\", self.call_agent_node_1_function)\n",
        "        # graph.add_node(\"action_node_1\", self.take_action_function)\n",
        "\n",
        "        # Placeholder to create edges (simple edge and conditional edge). Example:\n",
        "        # graph.add_conditional_edges(\n",
        "        #     \"agent_node\",\n",
        "        #     self.exists_action,\n",
        "        #     {True: \"action_node_1\", False: END}\n",
        "        # )\n",
        "        # graph.add_edge(\"action_node_1\", \"agent_node_1\")\n",
        "\n",
        "        # Placeholder to set entry_point. Example:\n",
        "        # graph.set_entry_point(\"agent_node_1\")\n",
        "\n",
        "        self.graph = graph.compile()\n",
        "        self.tools = {t.name: t for t in tools}\n",
        "        self.model = model.bind_tools(tools)\n",
        "\n",
        "    def exists_action(self, state: AgentState):\n",
        "        result = state['messages'][-1]\n",
        "        return len(result.tool_calls) > 0\n",
        "\n",
        "    # Placeholder to define the function to call agent. Example:\n",
        "    # def call_agent_node_1_function (self, state: AgentState):\n",
        "    #     messages = state['messages']\n",
        "    #     if self.system:\n",
        "    #         messages = [SystemMessage(content=self.system)] + messages\n",
        "    #     message = self.model.invoke(messages)\n",
        "    #     return {'messages': [message]}\n",
        "\n",
        "    def take_action_function (self, state: AgentState):\n",
        "        tool_calls = state['messages'][-1].tool_calls\n",
        "        results = []\n",
        "        for t in tool_calls:\n",
        "            print(f\"Calling: {t}\")\n",
        "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
        "                print(\"\\n ....bad tool name....\")\n",
        "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
        "            else:\n",
        "                result = self.tools[t['name']].invoke(t['args'])\n",
        "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "        print(\"Back to the model!\")\n",
        "        return {'messages': results}\n",
        "\n",
        "# Placeholder for system prompt. Example:\n",
        "# prompt = \"\"\"You are a smart building energy analysis. You can generate and debug code to do analysis and modeling based on users’ requests\"\"\"\n",
        "\n",
        "# Placeholder to define LLM foundation model and setup API keys. Example:\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=\"...\")\n",
        "\n",
        "abot = Agent(model, tool_list, system=prompt)\n",
        "\n",
        "# Placeholder to define LLM foundation model. Example:\n",
        "# user_input = \"Help me generate an energy usage trend line plots for the building data stored locally: data/building_data.csv\"\n",
        "\n",
        "messages = [HumanMessage(content= user_input)]\n",
        "result = abot.graph.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "id": "hc-pVXeU9Tdc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}